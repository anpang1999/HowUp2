{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # For interacting with the operating system (e.g., file paths)\n",
    "import re  # For regular expression operations\n",
    "import pdfplumber  # For extracting text from PDF files\n",
    "from dotenv import load_dotenv  # For loading environment variables from a `.env` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain Core Libraries\n",
    "from langchain.schema import Document  # Document schema for managing structured text data\n",
    "from langchain.embeddings import OpenAIEmbeddings  # Embeddings using OpenAI models\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Text splitting into chunks\n",
    "\n",
    "# LangChain Community Libraries\n",
    "from langchain_community.vectorstores import FAISS  # Vector store for semantic search using FAISS\n",
    "from langchain_core.documents import Document  # Another Document schema (to avoid duplication, remove one)\n",
    "from langchain_core.output_parsers import StrOutputParser  # Converts outputs to strings\n",
    "from langchain_core.runnables import RunnablePassthrough  # Pass-through for inputs in chains\n",
    "from langchain_core.prompts import PromptTemplate  # For creating prompt templates for models\n",
    "\n",
    "# LangChain OpenAI-Specific Libraries\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI  # OpenAI Embeddings and Chat API wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAGAS Core Libraries\n",
    "from ragas import evaluate  # Main evaluation function for RAGAS\n",
    "from ragas.llms import LangchainLLMWrapper  # Wrapper for LLMs to ensure compatibility with RAGAS\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper  # Wrapper for embeddings compatibility\n",
    "from ragas.testset.generator import TestsetGenerator  # Testset generator for creating question-answer pairs\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context, conditional  # Question type strategies\n",
    "from ragas.testset.extractor import KeyphraseExtractor  # Extracts key phrases from documents\n",
    "from ragas.testset.docstore import InMemoryDocumentStore  # Stores documents in memory for fast access\n",
    "from ragas.metrics import answer_relevancy, faithfulness, context_recall, context_precision  # Evaluation metrics\n",
    "\n",
    "from datasets import Dataset  # Hugging Face library for dataset manipulation and handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# ðŸ”¹ Global Variable Declaration\n",
    "documents = []  # Used as a global list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ Functions Used\n",
    "\n",
    "# ðŸ”¹ Function to List Files in a Folder\n",
    "def get_filenames_in_folder(folder_path):\n",
    "    \"\"\"Returns a list of all file names in the specified folder.\"\"\"\n",
    "    try:\n",
    "        filenames = [file for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))]\n",
    "        return filenames  # Return the list of file names\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "# ðŸ”¹ Function to Split PDF Files by Page\n",
    "def chunk_pdf_with_pdfplumber(file_path, start_page=1, end_page=-1):\n",
    "    \"\"\"Splits a PDF into chunks based on a specific page range and converts them into Document objects.\"\"\"\n",
    "    chunks = []\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        total_pages = len(pdf.pages)  # Get the total number of pages in the PDF\n",
    "        # Adjust end_page if it is negative\n",
    "        if end_page < 0:\n",
    "            end_page = total_pages + end_page + 1  # Calculate page count from the end\n",
    "        \n",
    "        # Process pages within the specified range\n",
    "        for page_num in range(start_page - 1, end_page):\n",
    "            page = pdf.pages[page_num]\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                # Clean the text (remove unnecessary characters)\n",
    "                cleaned_text = re.sub(r'\\n|\\r|\\t', ' ', text)  # Remove escape characters\n",
    "                cleaned_text = re.sub(r'í‘œ<\\d+-\\d+>', '', cleaned_text)  # Remove '<number-number>' patterns\n",
    "                cleaned_text = re.sub(r'â–¡| |â—‹', '', cleaned_text)  # Remove 'â–¡', ' ', 'â—‹'\n",
    "                cleaned_text = re.sub(r'<(ê·¸ë¦¼|í‘œ) \\d+-\\d+>', '', cleaned_text)  # Remove '<figure number-number>' patterns\n",
    "                \n",
    "                chunks.append({\n",
    "                    \"page_content\": cleaned_text.strip(),\n",
    "                    \"metadata\": {\n",
    "                        \"source_type\": \"pdf\",\n",
    "                        \"file_name\": file_path,\n",
    "                        \"page_number\": page_num + 1\n",
    "                    }\n",
    "                })\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# ðŸ”¹ Function to Add a New PDF File and Accumulate into Documents (Allow Duplicates)\n",
    "def add_pdf_to_documents(file_path, start_page=1, end_page=-1):\n",
    "    \"\"\"Reads a PDF file, converts it into Document objects, and appends to the global documents list (duplicates allowed).\"\"\"\n",
    "    global documents  # Use a global variable\n",
    "    chunk_dicts = chunk_pdf_with_pdfplumber(file_path, start_page, end_page)\n",
    "    \n",
    "    # ðŸ”¹ Convert each page of the PDF into a Document and append (duplicates allowed)\n",
    "    new_documents = [\n",
    "        Document(page_content=chunk[\"page_content\"], metadata=chunk[\"metadata\"])\n",
    "        for chunk in chunk_dicts\n",
    "    ]\n",
    "    \n",
    "    documents.extend(new_documents)  # Append new documents to the existing documents\n",
    "    print(f\"âœ… {len(new_documents)} chunks from the PDF '{file_path}' have been added to documents.\")\n",
    "    print(f\"ðŸ“‚ Total number of Documents: {len(documents)}\")\n",
    "\n",
    "    return new_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ Add PDF Files (Duplicates Allowed)\n",
    "file_list = get_filenames_in_folder('./pdfs')\n",
    "\n",
    "for file in file_list:\n",
    "    file_path = f\"./pdfs/{file}\"  # Path to the PDF file\n",
    "\n",
    "    # Add the PDF file twice (allowing duplicates)\n",
    "    add_pdf_to_documents(file_path, start_page=3, end_page=-2)\n",
    "\n",
    "    # Create a vector database\n",
    "    vectorstore = FAISS.from_documents(documents=documents, embedding=OpenAIEmbeddings())\n",
    "\n",
    "    # Save the database locally\n",
    "    vectorstore.save_local('./db/faiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ RAG-based Test Set Generation Pipeline\n",
    "\n",
    "# Generator\n",
    "generator_llm = ChatOpenAI(model='gpt-4o')\n",
    "\n",
    "# Critic\n",
    "critic_llm = ChatOpenAI(model='gpt-4o')\n",
    "\n",
    "# Embedding Model\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Wrapper for Embedding Model to Ensure Compatibility with RAGAS\n",
    "ragas_embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
    "\n",
    "# Model for Creating Keyphrase Extractor (Wrapper for RAGAS Compatibility)\n",
    "langchain_llm = LangchainLLMWrapper(ChatOpenAI(model='gpt-4o'))\n",
    "\n",
    "# Keyphrase Extractor: Identifies and Extracts Key Information from Documents\n",
    "Keyphrase_extractor = KeyphraseExtractor(llm=langchain_llm)\n",
    "\n",
    "# Chunking and Overlap Configuration for PDF Processing\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=400)\n",
    "\n",
    "# In-Memory Document Store Configuration\n",
    "docstore = InMemoryDocumentStore(\n",
    "    splitter=splitter,\n",
    "    embeddings=ragas_embeddings,\n",
    "    extractor=Keyphrase_extractor\n",
    ")\n",
    "\n",
    "# Generator Creation (Generates and Evaluates Simultaneously)\n",
    "# Generator Configuration with Four Components\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,  # Generator\n",
    "    critic_llm,     # Critic\n",
    "    ragas_embeddings,  # Embedding Model\n",
    "    docstore=docstore  # Document Store\n",
    ")\n",
    "\n",
    "# Distribution of Question Types\n",
    "distributions = {\n",
    "    simple: 0.4,  # Questions with a single clear answer\n",
    "    reasoning: 0.2,  # Questions requiring reasoning based on multiple clues\n",
    "    multi_context: 0.2,  # Questions requiring understanding multiple contexts\n",
    "    conditional: 0.2  # Conditional questions, requiring specific conditions\n",
    "}\n",
    "\n",
    "# ðŸ”¹ Generate Test Set\n",
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents=documents,  # âœ… Pass the document list\n",
    "    test_size=20,  # Number of question-answer sets to generate\n",
    "    distributions=distributions,  # Difficulty distribution of questions\n",
    "    with_debugging_logs=True,  # Enable debugging logs\n",
    "    raise_exceptions=False  # Do not halt on exceptions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ RAG-Based Question Answering Evaluation Pipeline\n",
    "\n",
    "test_df = testset.to_pandas()\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Prompt Template for Answering Questions\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an AI designed to answer questions using the given context. \n",
    "    Answer in the appropriate language for the context.\n",
    "    If you don't know the answer, respond with 'I don't know.'\n",
    "    \n",
    "    # Context: {context}\n",
    "    # Question: {question}\n",
    "    # Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# LLM for Question Answering\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "\n",
    "# Chain to Handle Context Retrieval, Question Answering, and Output Parsing\n",
    "chain = (\n",
    "    {'context': retriever, 'question': RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Batch Processing of Questions\n",
    "batch_dataset = []\n",
    "for question in test_dataset['question']:\n",
    "    batch_dataset.append(question)\n",
    "\n",
    "answer = chain.batch(batch_dataset)\n",
    "\n",
    "# Add or Update 'answer' Column in Test Dataset\n",
    "if 'answer' in test_dataset.column_names:\n",
    "    test_dataset = test_dataset.remove_columns(['answer']).add_column('answer', answer)\n",
    "else:\n",
    "    test_dataset = test_dataset.add_column('answer', answer)\n",
    "\n",
    "# Evaluate Model Performance\n",
    "result = evaluate(\n",
    "    dataset=test_dataset,\n",
    "    metrics=[\n",
    "        context_recall,    # How well the model recalls important context information\n",
    "        faithfulness,      # Factual correctness of the model's answer based on context\n",
    "        answer_relevancy,  # Relevance of the model's answer to the overall question\n",
    "        context_precision  # Precision in using necessary context information\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Convert Evaluation Results to DataFrame\n",
    "result_df = result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result\n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
